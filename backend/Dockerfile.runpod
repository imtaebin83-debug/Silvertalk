# ============================================================
# SilverTalk Worker Dockerfile - RunPod GPU Production
# ============================================================
# 용도: RunPod GPU 환경 전용 (AI 모델 로딩)
# 실행 환경: RunPod NVIDIA GPU (RTX 4090 등)
# ============================================================

FROM pytorch/pytorch:2.1.2-cuda11.8-cudnn8-runtime

# 작업 디렉토리
WORKDIR /app

# 시스템 종속성
RUN apt-get update && apt-get install -y \
    git \
    libsndfile1 \
    ffmpeg \
    libpq-dev \
    gcc \
    # PyAV 빌드용 FFmpeg 개발 라이브러리
    libavformat-dev \
    libavcodec-dev \
    libavdevice-dev \
    libavutil-dev \
    libswscale-dev \
    libswresample-dev \
    libavfilter-dev \
    && rm -rf /var/lib/apt/lists/*

# Python 패키지 설치 (전체 AI 모델 포함)
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 애플리케이션 코드 복사
COPY . /app

# 모델 디렉토리 생성
RUN mkdir -p /app/models

# 환경 변수 설정
ENV PYTHONUNBUFFERED=1
ENV DEPLOYMENT_MODE=CLOUD
ENV ENVIRONMENT=production
ENV MODELS_ROOT=/app/models
ENV CUDA_VISIBLE_DEVICES=0

# ✅ Coqui TTS 라이선스 자동 동의 (필수!)
ENV COQUI_TOS_AGREED=1

# Celery Worker 실행 (--include=worker.tasks 필수!)
CMD ["celery", "-A", "worker.celery_app", "worker", "--loglevel=info", "--concurrency=2", "--include=worker.tasks"]