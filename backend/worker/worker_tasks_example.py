"""
RunPod Workerìš© Celery Task ì˜ˆì‹œ
- process_audio: ìŒì„± íŒŒì¼ STT â†’ LLM â†’ TTS ì „ì²´ íŒŒì´í”„ë¼ì¸
- S3 ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬
"""
from celery import Task
from worker.celery_app import celery_app
from worker.s3_utils import download_from_s3, upload_to_s3, cleanup_temp_files
import logging
import uuid

logger = logging.getLogger(__name__)

@celery_app.task(name="worker.tasks.process_audio", bind=True)
def process_audio(
    self: Task,
    audio_s3_key: str,
    user_id: str,
    session_id: str,
    reference_voice_s3_key: str = None
) -> dict:
    """
    ìŒì„± ì²˜ë¦¬ ì „ì²´ íŒŒì´í”„ë¼ì¸
    
    Flow:
    1. S3ì—ì„œ ì‚¬ìš©ì ìŒì„± ë‹¤ìš´ë¡œë“œ
    2. Whisper STT ì‹¤í–‰
    3. Gemini LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±
    4. XTTS TTSë¡œ ìŒì„± í•©ì„±
    5. ê²°ê³¼ë¥¼ S3ì— ì—…ë¡œë“œ
    6. ì„ì‹œ íŒŒì¼ ì •ë¦¬
    
    Args:
        audio_s3_key: S3ì— ì €ì¥ëœ ì‚¬ìš©ì ìŒì„± íŒŒì¼ í‚¤
        user_id: ì‚¬ìš©ì ID
        session_id: ëŒ€í™” ì„¸ì…˜ ID
        reference_voice_s3_key: ì°¸ì¡° ìŒì„± íŒŒì¼ (XTTS í•™ìŠµìš©, ì„ íƒ)
    
    Returns:
        dict: {
            "transcription": str,  # STT ê²°ê³¼
            "response_text": str,  # LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            "response_audio_url": str,  # TTS ê²°ê³¼ S3 URL
            "task_id": str,  # Celery Task ID
            "status": "completed"
        }
    
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³ ë ¤ì‚¬í•­:
    - AI ëª¨ë¸ì€ worker ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ (load_models() í•¨ìˆ˜)
    - ì„ì‹œ íŒŒì¼ì€ ì²˜ë¦¬ í›„ ì¦‰ì‹œ ì‚­ì œ
    - GPU ë©”ëª¨ë¦¬ëŠ” Task ê°„ ê³µìœ  (ë™ì‹œì„±=1 ê¶Œì¥)
    """
    task_id = self.request.id
    logger.info(f"ğŸ¯ Task ì‹œì‘: {task_id} - User: {user_id}, Session: {session_id}")
    
    # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
    input_audio_path = f"/tmp/{task_id}_input.wav"
    output_audio_path = f"/tmp/{task_id}_output.wav"
    reference_voice_path = f"/tmp/{task_id}_reference.wav" if reference_voice_s3_key else None
    
    try:
        # ========================================
        # 1. S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        # ========================================
        logger.info("ğŸ“¥ Step 1: S3 íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
        download_from_s3(audio_s3_key, input_audio_path)
        
        if reference_voice_s3_key:
            download_from_s3(reference_voice_s3_key, reference_voice_path)
        
        # ========================================
        # 2. Whisper STT ì‹¤í–‰
        # ========================================
        # TODO: worker.tasks.load_models()ì—ì„œ ë¡œë“œëœ whisper_model ì‚¬ìš©
        # ì˜ˆì‹œ ì½”ë“œ (ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ tasks.py ì°¸ê³ ):
        #
        # from worker.tasks import whisper_model
        # segments, info = whisper_model.transcribe(
        #     input_audio_path,
        #     language="ko",
        #     beam_size=5
        # )
        # transcription = " ".join([seg.text for seg in segments])
        
        transcription = "[STT ê²°ê³¼ - ì‹¤ì œ êµ¬í˜„ í•„ìš”]"  # Stub
        logger.info(f"âœ… Step 2: STT ì™„ë£Œ - '{transcription[:50]}...'")
        
        # ========================================
        # 3. Gemini LLM ì‘ë‹µ ìƒì„±
        # ========================================
        # TODO: worker.tasks.load_models()ì—ì„œ ì´ˆê¸°í™”ëœ gemini_model ì‚¬ìš©
        # ì˜ˆì‹œ ì½”ë“œ:
        #
        # from worker.tasks import gemini_model
        # prompt = f"ì‚¬ìš©ì: {transcription}\nê°•ì•„ì§€ ì—­í• ë¡œ ë”°ëœ»í•˜ê²Œ ì‘ë‹µ:"
        # response = gemini_model.generate_content(prompt)
        # response_text = response.text
        
        response_text = "[LLM ì‘ë‹µ - ì‹¤ì œ êµ¬í˜„ í•„ìš”]"  # Stub
        logger.info(f"âœ… Step 3: LLM ì™„ë£Œ - '{response_text[:50]}...'")
        
        # ========================================
        # 4. XTTS TTS ìŒì„± í•©ì„±
        # ========================================
        # TODO: worker.tasks.load_models()ì—ì„œ ë¡œë“œëœ tts_model ì‚¬ìš©
        # ì˜ˆì‹œ ì½”ë“œ:
        #
        # from worker.tasks import tts_model
        # tts_model.tts_to_file(
        #     text=response_text,
        #     file_path=output_audio_path,
        #     speaker_wav=reference_voice_path,  # ì°¸ì¡° ìŒì„± (ì„ íƒ)
        #     language="ko"
        # )
        
        # Stub: ë¹ˆ íŒŒì¼ ìƒì„±
        with open(output_audio_path, "wb") as f:
            f.write(b"")  # ì‹¤ì œë¡œëŠ” TTS ê²°ê³¼ ì €ì¥
        logger.info(f"âœ… Step 4: TTS ì™„ë£Œ - {output_audio_path}")
        
        # ========================================
        # 5. ê²°ê³¼ë¥¼ S3ì— ì—…ë¡œë“œ
        # ========================================
        result_s3_key = f"audio/{user_id}/{session_id}/{task_id}_response.wav"
        response_audio_url = upload_to_s3(output_audio_path, result_s3_key)
        logger.info(f"âœ… Step 5: S3 ì—…ë¡œë“œ ì™„ë£Œ - {response_audio_url}")
        
        # ========================================
        # 6. ì„ì‹œ íŒŒì¼ ì •ë¦¬
        # ========================================
        cleanup_temp_files(
            input_audio_path,
            output_audio_path,
            reference_voice_path
        )
        
        # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
        return {
            "transcription": transcription,
            "response_text": response_text,
            "response_audio_url": response_audio_url,
            "task_id": task_id,
            "status": "completed"
        }
    
    except Exception as e:
        logger.error(f"âŒ Task ì‹¤íŒ¨: {task_id} - {str(e)}")
        
        # ì‹¤íŒ¨ ì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(
            input_audio_path,
            output_audio_path,
            reference_voice_path
        )
        
        # ì—ëŸ¬ ë°˜í™˜
        return {
            "status": "failed",
            "task_id": task_id,
            "error": str(e)
        }


# ============================================================
# ëª¨ë¸ ë¡œë”© (Worker ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰)
# ============================================================
# ì£¼ì˜: ì´ ë¶€ë¶„ì€ ê¸°ì¡´ worker/tasks.pyì˜ load_models() í•¨ìˆ˜ ì°¸ê³ 
# Worker ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í˜¸ì¶œ:
#   celery -A worker.celery_app worker --loglevel=info -E
#
# load_models()ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰:
# 1. whisper_model = WhisperModel(...)
# 2. tts_model = TTS(...).to(device)
# 3. gemini_model = genai.GenerativeModel(...)
#
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:
# - GPU 24GB ê¸°ì¤€: Whisper 3GB + XTTS 1.8GB + ì—¬ìœ  ê³µê°„
# - concurrency=2ë¡œ ì„¤ì • ê°€ëŠ¥ (ë™ì‹œ 2ê°œ Task)
# - concurrency=1 ê¶Œì¥ (ì•ˆì •ì„± ìš°ì„ )
