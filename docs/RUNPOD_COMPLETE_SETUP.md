# RunPod GPU Worker - ì™„ì „ ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”
RunPod GPU Workerì˜ ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ì„ ì‚¬ì „ ì ê²€í•˜ê³  ì„¤ì¹˜í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (3ë‹¨ê³„)

### 1ï¸âƒ£ í™˜ê²½ ì§„ë‹¨
```bash
cd /workspace
bash backend/worker/check_runpod_environment.sh
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ğŸ” RunPod GPU Worker í™˜ê²½ ì§„ë‹¨ ì‹œì‘...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š [1/8] GPU & CUDA ìƒíƒœ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ nvidia-smi ì‹¤í–‰ ê°€ëŠ¥: âœ… PASS
NVIDIA GeForce RTX 3090, 525.125.06, 24576 MiB
ğŸ”¹ CUDA ëŸ°íƒ€ì„ ê°ì§€: âœ… PASS

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ§  [3/8] cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ (í•„ìˆ˜!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ libcudnn_ops_infer.so.8: âŒ FAIL
  âš ï¸  Whisper CUDA ì‹¤í–‰ ë¶ˆê°€! cuDNN ì„¤ì¹˜ í•„ìš”
```

---

### 2ï¸âƒ£ ëˆ„ë½ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¼ê´„ ì„¤ì¹˜
```bash
bash backend/worker/setup_runpod_complete.sh
```

**ì„¤ì¹˜ í•­ëª©**:
- âœ… cuDNN 8.9.7 (CUDA 12.xìš©)
- âœ… libcublas-12-0, libcublasLt-12-0
- âœ… FFmpeg (ì˜¤ë””ì˜¤ ì²˜ë¦¬)
- âœ… CTranslate2 (CUDA ì§€ì› ì¬ë¹Œë“œ)
- âœ… Faster-Whisper (ìµœì‹  ë²„ì „)

**ì†Œìš” ì‹œê°„**: ì•½ 5-10ë¶„
**í•„ìš” ìš©ëŸ‰**: ~500MB

---

### 3ï¸âƒ£ ì¬ì§„ë‹¨ ë° Worker ì‹¤í–‰
```bash
# ì¬ì§„ë‹¨
bash backend/worker/check_runpod_environment.sh

# ëª¨ë“  ê²€ì‚¬ í†µê³¼ ì‹œ
celery -A worker.celery_app worker --loglevel=info --concurrency=4
```

---

## ğŸ›¡ï¸ ì—ëŸ¬ë³„ í•´ê²° ê°€ì´ë“œ

### âŒ `libcudnn_ops_infer.so.8: cannot open shared object file`
**ì¦ìƒ**: Whisper CUDA ì‹¤í–‰ ì¤‘ Worker í”„ë¡œì„¸ìŠ¤ SIGABRT
**ì›ì¸**: cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜
**í•´ê²°**:
```bash
apt-get update
apt-get install -y libcudnn8=8.9.7.29-1+cuda12.2 libcudnn8-dev=8.9.7.29-1+cuda12.2
pip uninstall -y ctranslate2 && pip install --no-cache-dir ctranslate2==4.0.0
```

**ê²€ì¦**:
```bash
ldconfig -p | grep libcudnn_ops_infer.so.8
# ì¶œë ¥: libcudnn_ops_infer.so.8 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8
```

---

### âŒ `Library libcublas.so.12 is not found`
**ì›ì¸**: CUDA í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½
**í•´ê²°**:
```bash
apt-get install -y libcublas-12-0 libcublasLt-12-0 cuda-cudart-12-0
```

---

### âŒ FFmpeg ê´€ë ¨ ì—ëŸ¬
**ì¦ìƒ**: `ffmpeg: command not found` ë˜ëŠ” ì˜¤ë””ì˜¤ ë””ì½”ë”© ì‹¤íŒ¨
**í•´ê²°**:
```bash
apt-get install -y ffmpeg
ffmpeg -version  # ê²€ì¦
```

---

### âŒ Redis ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**: `ConnectionError: Error connecting to Redis`
**ì›ì¸**: í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ ë˜ëŠ” Upstash ì ‘ê·¼ ë¶ˆê°€
**í•´ê²°**:
```bash
# .env íŒŒì¼ í™•ì¸
cat /workspace/.env | grep REDIS

# í™˜ê²½ë³€ìˆ˜ í™•ì¸
echo $REDIS_URL
echo $REDIS_PASSWORD

# ì—°ê²° í…ŒìŠ¤íŠ¸
python3 -c "
from celery import Celery
app = Celery(broker='rediss://default:YOUR_PASSWORD@new-grizzly-7377.upstash.io:6379')
print(app.control.inspect().stats())
"
```

---

## ğŸ” ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ìƒì„¸

### `check_runpod_environment.sh`
**8ê°€ì§€ ì²´í¬ í•­ëª©**:
1. GPU & CUDA ìƒíƒœ (nvidia-smi, torch.cuda)
2. CUDA í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (libcublas, libcublasLt)
3. cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ (libcudnn_ops_infer.so.8) â­
4. FFmpeg ì„¤ì¹˜
5. Python í™˜ê²½ (ë²„ì „, venv í™œì„±í™”)
6. Python íŒ¨í‚¤ì§€ (torch, faster-whisper, ctranslate2 ë“±)
7. Whisper ëª¨ë¸ íŒŒì¼
8. Redis ì—°ê²° (Celery Broker)

**ì¢…ë£Œ ì½”ë“œ**:
- `0`: ëª¨ë“  ê²€ì‚¬ í†µê³¼
- `1`: 1ê°œ ì´ìƒ ì‹¤íŒ¨ (ìˆ˜ì • í•„ìš”)

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | CPU (int8) | CUDA (float16) | ê°œì„ ìœ¨ |
|------|-----------|----------------|--------|
| STT ì²˜ë¦¬ ì‹œê°„ | ~15-20ì´ˆ | ~2-3ì´ˆ | **5-7ë°°** |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 2GB | 4GB | - |
| ì „ë ¥ ì†Œë¹„ | ë‚®ìŒ | ë†’ìŒ | - |

**ê¶Œì¥**: RunPod GPU ì‚¬ìš© ì‹œ CUDA í•„ìˆ˜ (ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥)

---

## ğŸ”§ ì½”ë“œ ê°œì„  ì‚¬í•­

### `tasks.py` - cuDNN ì‚¬ì „ ì²´í¬ ê°•í™”
```python
# CUDA ì‹œë„ (cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ì „ ì²´í¬ í¬í•¨)
if device == "cuda":
    try:
        # cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¡´ì¬ ì—¬ë¶€ ì‚¬ì „ ì²´í¬
        import ctypes
        ctypes.CDLL("libcudnn_ops_infer.so.8")
        logger.info("âœ… cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ì™„ë£Œ")
        
        whisper_model = WhisperModel(...)
    
    except (OSError, Exception) as cuda_error:
        logger.warning(f"âš ï¸ CUDA/cuDNN ë¡œë”© ì‹¤íŒ¨: {cuda_error}")
        logger.warning("âš ï¸ CPU ëª¨ë“œë¡œ ê°•ì œ ì „í™˜")
        whisper_model = WhisperModel(device="cpu", compute_type="int8", ...)
```

**ê°œì„  íš¨ê³¼**:
- âŒ ê¸°ì¡´: WhisperModel ë¡œë”© í›„ STT ì‹¤í–‰ ì¤‘ SIGABRT (í”„ë¡œì„¸ìŠ¤ ì£½ìŒ)
- âœ… ê°œì„ : cuDNN ì‚¬ì „ ì²´í¬ â†’ ì—†ìœ¼ë©´ ì¦‰ì‹œ CPU fallback (ì•ˆì •ì„± â¬†ï¸)

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Worker ì‹œì‘ ì „)

- [ ] GPU ì¸ì‹ (`nvidia-smi` ì •ìƒ ì¶œë ¥)
- [ ] CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (libcublas, libcublasLt)
- [ ] **cuDNN ì„¤ì¹˜** (`ldconfig -p | grep libcudnn_ops_infer.so.8`)
- [ ] FFmpeg ì„¤ì¹˜ (`ffmpeg -version`)
- [ ] Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ (`pip list | grep faster-whisper`)
- [ ] Redis ì—°ê²° í…ŒìŠ¤íŠ¸ (í™˜ê²½ë³€ìˆ˜ í™•ì¸)
- [ ] Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê³µê°„ (Volume: `/workspace/models/`)
- [ ] ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼ (`check_runpod_environment.sh`)

---

## ğŸ†˜ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… í”Œë¡œìš°

```
Worker ì‹œì‘ ì‹¤íŒ¨
    â”‚
    â”œâ”€> ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    â”‚   bash backend/worker/check_runpod_environment.sh
    â”‚
    â”œâ”€> cuDNN ì—ëŸ¬?
    â”‚   â””â”€> setup_runpod_complete.sh ì‹¤í–‰
    â”‚
    â”œâ”€> Python íŒ¨í‚¤ì§€ ëˆ„ë½?
    â”‚   â””â”€> pip install -r backend/requirements.txt
    â”‚
    â”œâ”€> Redis ì—°ê²° ì‹¤íŒ¨?
    â”‚   â””â”€> .env íŒŒì¼ í™•ì¸, í™˜ê²½ë³€ìˆ˜ ì¬ì„¤ì •
    â”‚
    â””â”€> ì¬ì§„ë‹¨ â†’ Worker ì¬ì‹œì‘
```

---

## ğŸ“ ì§€ì›

**ë¡œê·¸ í™•ì¸ ëª…ë ¹ì–´**:
```bash
# Worker ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
celery -A worker.celery_app worker --loglevel=info

# GPU ìƒíƒœ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
htop
```

**ë””ë²„ê¹… ëª¨ë“œ**:
```bash
# ìƒì„¸ ë¡œê·¸ (ë””ë²„ê·¸)
celery -A worker.celery_app worker --loglevel=debug --concurrency=1
```

---

## âœ… ì„¤ì¹˜ ì™„ë£Œ í™•ì¸

**ì„±ê³µ ë¡œê·¸ ì˜ˆì‹œ**:
```
[2026-01-28 12:00:00,000: INFO] ğŸš€ GPU ê°ì§€: NVIDIA GeForce RTX 3090 - CUDA ëª¨ë“œ í™œì„±í™”
[2026-01-28 12:00:01,000: INFO] âœ… cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ì™„ë£Œ
[2026-01-28 12:00:05,000: INFO] âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ (model=medium, device=cuda, path=/workspace/models/whisper)
[2026-01-28 12:00:06,000: INFO] âœ… Gemini 1.5 Flash ì´ˆê¸°í™” ì™„ë£Œ
[2026-01-28 12:00:06,000: INFO] celery@runpod-worker ready.
```

ì´ì œ ìŒì„± ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œ **2-3ì´ˆ** ë‚´ ì™„ë£Œë©ë‹ˆë‹¤! ğŸš€
