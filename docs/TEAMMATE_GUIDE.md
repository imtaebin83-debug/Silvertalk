# ğŸ¤ íŒ€ì›ìš© ê°€ì´ë“œ: S3 ì—°ë™ ì‘ì—… ì‹œì‘ ì „ ì½ì–´ì£¼ì„¸ìš”

## ğŸ“¢ ì•Œë¦¼: í”„ë¡œë•ì…˜ ì¸í”„ë¼ ë³€ê²½ ì‚¬í•­

ì € (imtae)ê°€ ë‹¤ìŒ ì‘ì—…ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤:
- âœ… Upstash Redis (Tokyo) ì—°ë™
- âœ… RunPod GPU Worker ì„¤ì •
- âœ… AWS RDS PostgreSQL ì¤€ë¹„

**ì¤‘ìš”: ì—¬ëŸ¬ë¶„ì˜ ë¡œì»¬ ê°œë°œ í™˜ê²½ì€ ì „í˜€ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!** ğŸ¯

## âœ… ë³€ê²½ë˜ì§€ ì•Šì€ ê²ƒ (ì•ˆì‹¬í•˜ê³  ê³„ì† ì‘ì—…í•˜ì„¸ìš”)

### ë¡œì»¬ ê°œë°œ í™˜ê²½
```bash
# ê¸°ì¡´ ëª…ë ¹ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
docker-compose up
docker-compose down
docker-compose logs -f
```

### ê¸°ì¡´ íŒŒì¼ë“¤
- `docker-compose.yml` - ë³€ê²½ ì—†ìŒ (ë¡œì»¬ Redis, PostgreSQL ê·¸ëŒ€ë¡œ)
- `backend/Dockerfile.api` - ë³€ê²½ ì—†ìŒ
- `backend/Dockerfile.worker` - ë³€ê²½ ì—†ìŒ
- `backend/requirements.txt` - ë³€ê²½ ì—†ìŒ

### ë¡œì»¬ ì„œë¹„ìŠ¤
```
localhost:8000 - FastAPI (ê·¸ëŒ€ë¡œ)
localhost:5432 - PostgreSQL (ê·¸ëŒ€ë¡œ)
localhost:6379 - Redis (ê·¸ëŒ€ë¡œ)
localhost:5555 - Flower (ê·¸ëŒ€ë¡œ)
```

## ğŸ†• ì¶”ê°€ëœ ê²ƒ (í”„ë¡œë•ì…˜ ì „ìš©)

### ìƒˆë¡œìš´ íŒŒì¼ë“¤ (ë¬´ì‹œí•´ë„ ë¨)
```
docker-compose.production.yml  # EC2 í”„ë¡œë•ì…˜ ì „ìš©
backend/Dockerfile.runpod      # RunPod GPU Worker ì „ìš©
.env.ec2                        # EC2 í™˜ê²½ ë³€ìˆ˜ (Git ì œì™¸)
.env.runpod                     # RunPod í™˜ê²½ ë³€ìˆ˜ (Git ì œì™¸)
.env.production.example         # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ
docs/RUNPOD_SETUP.md            # RunPod ì„¤ì • ê°€ì´ë“œ
docs/RUNPOD_DEPLOY.md           # RunPod ë°°í¬ ê°€ì´ë“œ
docs/DEPLOYMENT_CHECKLIST.md    # ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
docs/TEAMMATE_GUIDE.md          # ì´ íŒŒì¼
```

### config.py ë³€ê²½ ì‚¬í•­
`backend/common/config.py`ì— ë‹¤ìŒì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤:

```python
# ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œ (í”„ë¡œë•ì…˜ ì „ìš©)
DEPLOYMENT_MODE: str = "LOCAL"  # LOCAL or CLOUD
STORAGE_BACKEND: str = "LOCAL"  # LOCAL or S3
RUNPOD_SSH_HOST: Optional[str] = None
RUNPOD_SSH_PORT: Optional[int] = None
RUNPOD_SSH_KEY_PATH: Optional[str] = None
UPSTASH_REDIS_URL: Optional[str] = None
PROD_DATABASE_URL: Optional[str] = None

# ë™ì  ì†ì„± (ë¡œì»¬ ê°œë°œì—ëŠ” ì˜í–¥ ì—†ìŒ)
@property
def redis_url(self):
    if self.DEPLOYMENT_MODE == "CLOUD" and self.UPSTASH_REDIS_URL:
        return self.UPSTASH_REDIS_URL
    return self.REDIS_URL  # ë¡œì»¬ Redis (ê¸°ì¡´)

@property
def database_url(self):
    if self.DEPLOYMENT_MODE == "CLOUD" and self.PROD_DATABASE_URL:
        return self.PROD_DATABASE_URL
    return self.DATABASE_URL  # ë¡œì»¬ PostgreSQL (ê¸°ì¡´)
```

**ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìë™ìœ¼ë¡œ ê¸°ì¡´ ì„¤ì • ì‚¬ìš©ë©ë‹ˆë‹¤.**

## ğŸ¯ S3 ì—°ë™ ì‘ì—… ì‹œì‘í•˜ê¸°

### 1. ìµœì‹  ì½”ë“œ Pull
```bash
cd c:\Users\imtae\OneDrive\ë°”íƒ• í™”ë©´\2026madcamp\silvertalk
git pull origin main  # ë˜ëŠ” feature/runpod-upstash
```

### 2. S3 íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ë¡œì»¬ì—ì„œ)
```bash
# backend ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd backend

# boto3 ì„¤ì¹˜ (Poetry ì‚¬ìš©)
poetry add boto3

# ë˜ëŠ” requirements.txtì— ì¶”ê°€
echo "boto3>=1.34.0" >> requirements.txt
pip install boto3
```

### 3. S3 ì„¤ì • ì½”ë“œ ì‘ì„±

#### 3.1. S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
`backend/common/s3_client.py` íŒŒì¼ ìƒì„±:

```python
import boto3
from botocore.exceptions import ClientError
from .config import settings

def get_s3_client():
    """S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if settings.STORAGE_BACKEND != "S3":
        return None
    
    return boto3.client(
        's3',
        aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
        aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
        region_name=settings.AWS_REGION
    )

def upload_file_to_s3(file_path: str, s3_key: str, bucket: str = None) -> str:
    """íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  URL ë°˜í™˜"""
    if bucket is None:
        bucket = settings.S3_BUCKET_NAME
    
    s3_client = get_s3_client()
    if s3_client is None:
        raise ValueError("S3 is not configured")
    
    try:
        s3_client.upload_file(file_path, bucket, s3_key)
        url = f"https://{bucket}.s3.{settings.AWS_REGION}.amazonaws.com/{s3_key}"
        return url
    except ClientError as e:
        raise Exception(f"S3 upload failed: {str(e)}")

def download_file_from_s3(s3_key: str, local_path: str, bucket: str = None):
    """S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    if bucket is None:
        bucket = settings.S3_BUCKET_NAME
    
    s3_client = get_s3_client()
    if s3_client is None:
        raise ValueError("S3 is not configured")
    
    try:
        s3_client.download_file(bucket, s3_key, local_path)
    except ClientError as e:
        raise Exception(f"S3 download failed: {str(e)}")
```

#### 3.2. í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€
`.env` íŒŒì¼ (ë¡œì»¬ ê°œë°œìš©):

```bash
# S3 ì„¤ì • (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
STORAGE_BACKEND=LOCAL  # ë¡œì»¬ì—ì„œëŠ” LOCAL ìœ ì§€
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=ap-northeast-1
S3_BUCKET_NAME=silvertalk-prod
```

#### 3.3. Routerì—ì„œ S3 ì‚¬ìš©
`backend/app/routers/gallery.py` ìˆ˜ì • ì˜ˆì‹œ:

```python
from common.s3_client import upload_file_to_s3
from common.config import settings

@router.post("/upload")
async def upload_photo(file: UploadFile = File(...)):
    # 1. ì„ì‹œ íŒŒì¼ ì €ì¥
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        f.write(await file.read())
    
    # 2. S3 ì—…ë¡œë“œ (í”„ë¡œë•ì…˜) ë˜ëŠ” ë¡œì»¬ ì €ì¥ (ê°œë°œ)
    if settings.STORAGE_BACKEND == "S3":
        s3_key = f"photos/{user_id}/{photo_id}.jpg"
        photo_url = upload_file_to_s3(temp_path, s3_key)
    else:
        # ë¡œì»¬ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
        photo_url = f"./data/photos/{photo_id}.jpg"
        shutil.copy(temp_path, photo_url)
    
    # 3. DBì— URL ì €ì¥
    photo = Photo(id=photo_id, url=photo_url, user_id=user_id)
    db.add(photo)
    db.commit()
    
    return {"photo_url": photo_url}
```

### 4. ë¡œì»¬ í…ŒìŠ¤íŠ¸

```bash
# Docker ë‹¤ì‹œ ì‹œì‘ (boto3 ì„¤ì¹˜ ë°˜ì˜)
docker-compose down
docker-compose build
docker-compose up

# API í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/gallery/upload \
  -F "file=@test_photo.jpg" \
  -F "user_id=test-user"

# ë¡œê·¸ í™•ì¸
docker logs silvertalk-worker -f
```

### 5. Git Commit & Push

```bash
git add backend/common/s3_client.py
git add backend/app/routers/gallery.py
git add backend/requirements.txt  # boto3 ì¶”ê°€ëœ ê²½ìš°
git commit -m "feat: add S3 integration for photo storage"
git push origin main
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. .env íŒŒì¼ ê´€ë¦¬
```bash
# ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ë§ ê²ƒ!
.env
.env.ec2
.env.runpod
.env.production

# ì»¤ë°‹í•´ë„ ë¨ (ì˜ˆì‹œ íŒŒì¼)
.env.example
.env.production.example
```

### 2. ë¡œì»¬ê³¼ í”„ë¡œë•ì…˜ ë¶„ë¦¬
```python
# config.pyì˜ ë™ì  ì„¤ì • í™œìš©
if settings.STORAGE_BACKEND == "S3":
    # S3 ì‚¬ìš© (í”„ë¡œë•ì…˜)
    upload_to_s3()
else:
    # ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ (ê°œë°œ)
    save_locally()
```

### 3. EC2ì—ì„œ S3 Role ì‚¬ìš© (ì¶”ì²œ)
EC2 IAM Roleì„ ì‚¬ìš©í•˜ë©´ Access Key ë¶ˆí•„ìš”:

```python
# EC2ì—ì„œëŠ” ìë™ìœ¼ë¡œ Role ì‚¬ìš©
s3_client = boto3.client('s3')  # Access Key ì—†ì´ ê°€ëŠ¥
```

## ğŸ“Š ì‘ì—… íë¦„ë„

```
[ë¡œì»¬ ê°œë°œ]
1. Git Pull
2. boto3 ì„¤ì¹˜
3. s3_client.py ì‘ì„±
4. Routerì—ì„œ S3 í•¨ìˆ˜ í˜¸ì¶œ
5. ë¡œì»¬ í…ŒìŠ¤íŠ¸ (STORAGE_BACKEND=LOCAL)
6. Git Commit & Push

[EC2 ë°°í¬ - imtae ë‹´ë‹¹]
1. EC2ì—ì„œ Git Pull
2. .env.ec2ì— S3 ì„¤ì • ì¶”ê°€
   STORAGE_BACKEND=S3
   S3_BUCKET_NAME=silvertalk-prod
3. IAM Role ì—°ê²° (Access Key ëŒ€ì‹ )
4. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
5. í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸
```

## ğŸ¯ ì™„ë£Œ ê¸°ì¤€

- [x] S3 í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ ì‘ì„±
- [x] Gallery Routerì— S3 ì—…ë¡œë“œ í•¨ìˆ˜ í†µí•©
- [x] ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ (STORAGE_BACKEND=LOCAL)
- [x] Git Push ì™„ë£Œ

**í”„ë¡œë•ì…˜ ë°°í¬ëŠ” ì œê°€ (imtae) ë‹´ë‹¹í•˜ë‹ˆ ì‹ ê²½ ì“°ì§€ ë§ˆì„¸ìš”!**

## ğŸ’¬ ì†Œí†µ

ì‘ì—… ì¤‘ ê¶ê¸ˆí•œ ì :
1. Discord/Slackì— ë©”ì‹œì§€
2. Git Issues ë“±ë¡
3. ì½”ë“œ ë¦¬ë·° ìš”ì²­ (PR)

**í™”ì´íŒ…! S3 ì—°ë™ ì‘ì—… ì‘ì›í•©ë‹ˆë‹¤!** ğŸš€

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Boto3 Documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)
- [AWS S3 Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/userguide/best-practices.html)
- ë¡œì»¬ í…ŒìŠ¤íŠ¸: `STORAGE_BACKEND=LOCAL` ìœ ì§€
- í”„ë¡œë•ì…˜: imtaeê°€ `STORAGE_BACKEND=S3` ì„¤ì •