# RunPod ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## âœ… Pod ìƒì„± ì™„ë£Œ í›„ ì¦‰ì‹œ í•  ì¼

### 1. ì›¹ í„°ë¯¸ë„ í™œì„±í™” (30ì´ˆ)
```
Pod ìƒì„¸ í˜ì´ì§€ â†’ Connect íƒ­
â†’ Web terminal ì„¹ì…˜
â†’ "Enable web terminal" í† ê¸€ í´ë¦­
â†’ í„°ë¯¸ë„ ì°½ ì—´ë¦¼ ëŒ€ê¸°
```

### 2. GPU í™•ì¸ (í„°ë¯¸ë„ì—ì„œ)
```bash
nvidia-smi

# ì¶œë ¥ í™•ì¸:
# - RTX 3090 í‘œì‹œ
# - 24GB VRAM
# - CUDA Version: 11.8
```

### 3. ì €ì¥ì†Œ í´ë¡ 
```bash
# Git ì„¤ì¹˜ í™•ì¸
git --version

# ì €ì¥ì†Œ í´ë¡  (GitHub URLë¡œ ë³€ê²½)
git clone https://github.com/YOUR_USERNAME/silvertalk.git

# ë””ë ‰í† ë¦¬ ì´ë™
cd silvertalk/backend
```

### 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
nano .env

# ë‹¤ìŒ ë‚´ìš© ì…ë ¥:
```

**íŒ€ì›ì—ê²Œ ë°›ì„ ì •ë³´:**
```bash
# ë°°í¬ ëª¨ë“œ
DEPLOYMENT_MODE=CLOUD
CUDA_VISIBLE_DEVICES=0

# Redis (Upstash)
UPSTASH_REDIS_URL=rediss://default:xxxxx@xxxxx.upstash.io:6379

# Database (RDS)
PROD_DATABASE_URL=postgresql://username:password@rds-endpoint:5432/silvertalk

# S3
STORAGE_BACKEND=S3
AWS_ACCESS_KEY_ID=AKIAxxxxx
AWS_SECRET_ACCESS_KEY=xxxxxx
AWS_REGION=ap-northeast-1
S3_BUCKET_NAME=silvertalk-prod

# Gemini API
GEMINI_API_KEY=your_gemini_key
```

**Nano í¸ì§‘ê¸° ì‚¬ìš©ë²•:**
```
1. ìœ„ ë‚´ìš© ë¶™ì—¬ë„£ê¸° (Ctrl+Shift+V)
2. ì‹¤ì œ ê°’ìœ¼ë¡œ ìˆ˜ì •
3. Ctrl+O (ì €ì¥)
4. Enter (íŒŒì¼ëª… í™•ì¸)
5. Ctrl+X (ì¢…ë£Œ)
```

### 5. ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (5ë¶„)
```bash
apt-get update
apt-get install -y git ffmpeg libsndfile1 nano screen

# ì„¤ì¹˜ í™•ì¸
ffmpeg -version
```

### 6. Python ì˜ì¡´ì„± ì„¤ì¹˜ (10-15ë¶„)
```bash
# requirements.txtë¡œ ì„¤ì¹˜
pip install -r requirements.txt

# ì§„í–‰ë¥  í™•ì¸ (ëŠë¦´ ìˆ˜ ìˆìŒ, ì •ìƒ)
# - torch: ì´ë¯¸ ì„¤ì¹˜ë¨ (PyTorch í…œí”Œë¦¿)
# - TTS: 1.8GB ë‹¤ìš´ë¡œë“œ
# - faster-whisper: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

# ì„¤ì¹˜ ì™„ë£Œ í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"
# True ì¶œë ¥ë˜ì–´ì•¼ í•¨

python -c "from TTS.api import TTS; print('TTS OK')"
# TTS OK ì¶œë ¥ë˜ì–´ì•¼ í•¨
```

### 7. Celery Worker ì‹œì‘ (í…ŒìŠ¤íŠ¸)
```bash
# í¬ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)
celery -A worker.celery_app worker --loglevel=info --concurrency=2

# ì„±ê³µ ë©”ì‹œì§€ í™•ì¸:
# - "celery@territorial_amaranth_mastodon ready."
# - "Connected to rediss://..."
# - "Task registered: ..."

# GPU ë©”ëª¨ë¦¬ í• ë‹¹ ë¡œê·¸ í™•ì¸:
# - Loading Whisper model...
# - Loading XTTS model...

# Ctrl+Cë¡œ ì¤‘ì§€
```

### 8. Screenìœ¼ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
```bash
# Screen ì„¸ì…˜ ìƒì„±
screen -S celery

# Celery Worker ì‹œì‘
celery -A worker.celery_app worker --loglevel=info --concurrency=2

# ì„¸ì…˜ ë¶„ë¦¬ (WorkerëŠ” ê³„ì† ì‹¤í–‰)
# Ctrl+A, ê·¸ ë‹¤ìŒ D í‚¤

# ì„¸ì…˜ ëª©ë¡ í™•ì¸
screen -ls
# ì¶œë ¥: 1234.celery (Detached)

# ë‹¤ì‹œ ì—°ê²° (ë¡œê·¸ í™•ì¸ìš©)
screen -r celery

# ë‹¤ì‹œ ë¶„ë¦¬
# Ctrl+A, D
```

### 9. ëª¨ë‹ˆí„°ë§

#### GPU ì‚¬ìš©ë¥ 
```bash
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ë˜ëŠ” 1íšŒ í™•ì¸
nvidia-smi

# í™•ì¸ ì‚¬í•­:
# - GPU-Util: 0-100%
# - Memory-Usage: /24576MiB
# - Processes: python í”„ë¡œì„¸ìŠ¤
```

#### Celery ë¡œê·¸
```bash
# Screen ì„¸ì…˜ í™•ì¸
screen -r celery

# ë¡œê·¸ ì¶œë ¥:
# - Task ìˆ˜ì‹  ë©”ì‹œì§€
# - AI ëª¨ë¸ ì‹¤í–‰ ë¡œê·¸
# - ì—ëŸ¬ ë°œìƒ ì‹œ Traceback
```

#### EC2 Flower ëŒ€ì‹œë³´ë“œ
```
ë¸Œë¼ìš°ì €: http://your-ec2-ip:5555

í™•ì¸ ì‚¬í•­:
- Workers: territorial_amaranth_mastodon (ì˜¨ë¼ì¸)
- Tasks: Active, Completed, Failed ìˆ˜
- Task ìƒì„¸ ë¡œê·¸
```

### 10. í†µí•© í…ŒìŠ¤íŠ¸ (EC2ì—ì„œ)

```bash
# EC2 SSH ì ‘ì†
ssh -i your-key.pem ubuntu@your-ec2-ip

# API í…ŒìŠ¤íŠ¸ (ìŒì„± ì—…ë¡œë“œ)
curl -X POST http://localhost:8000/chat/sessions \
  -H "Content-Type: multipart/form-data" \
  -F "user_id=test-user" \
  -F "audio_file=@test_audio.wav"

# ì‘ë‹µ í™•ì¸:
{
  "task_id": "abc123...",
  "status": "processing"
}
```

**RunPodì—ì„œ ë¡œê·¸ í™•ì¸:**
```bash
screen -r celery

# ì¶œë ¥ ì˜ˆì‹œ:
[INFO] Task chat.process_audio[abc123] received
[INFO] Loading audio file from S3...
[INFO] Running Whisper STT...
[INFO] Transcription: "ì•ˆë…•í•˜ì„¸ìš”"
[INFO] Calling Gemini API...
[INFO] Running XTTS TTS...
[INFO] Uploading result to S3...
[INFO] Task completed in 15.2s
```

## âœ… ì„±ê³µ ê¸°ì¤€

- [x] nvidia-smië¡œ RTX 3090 í™•ì¸
- [x] Pythonì—ì„œ CUDA ì‚¬ìš© ê°€ëŠ¥
- [x] Celery Worker ì‹œì‘ ì„±ê³µ
- [x] Upstash Redis ì—°ê²° í™•ì¸
- [x] RDS PostgreSQL ì—°ê²° í™•ì¸
- [x] Whisper ëª¨ë¸ ë¡œë”© ì„±ê³µ
- [x] XTTS ëª¨ë¸ ë¡œë”© ì„±ê³µ
- [x] S3 ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [x] EC2 â†’ RunPod Task ì²˜ë¦¬ í™•ì¸

## ğŸš¨ ë¬¸ì œ í•´ê²°

### Q: pip installì´ ë§¤ìš° ëŠë¦¼
```bash
# ì •ìƒì…ë‹ˆë‹¤. TTS 1.8GB ë‹¤ìš´ë¡œë“œ ì¤‘
# 10-15ë¶„ ëŒ€ê¸°

# ì§„í–‰ ìƒí™© í™•ì¸
pip list | grep TTS
```

### Q: CUDA out of memory
```bash
# concurrency ì¤„ì´ê¸°
celery -A worker.celery_app worker --loglevel=info --concurrency=1

# ëª¨ë¸ ìºì‹± í™•ì¸
ls ~/.cache/huggingface
```

### Q: Redis ì—°ê²° ì‹¤íŒ¨
```bash
# .env íŒŒì¼ í™•ì¸
cat .env | grep UPSTASH

# SSL ì—°ê²° í™•ì¸ (rediss:// ë¡œ ì‹œì‘í•´ì•¼ í•¨)
# íŒ€ì›ì—ê²Œ Upstash URL ì¬í™•ì¸
```

### Q: Screen ì„¸ì…˜ ì¢…ë£Œë¨
```bash
# ì„¸ì…˜ ëª©ë¡ í™•ì¸
screen -ls

# ì—†ìœ¼ë©´ ë‹¤ì‹œ ì‹œì‘
screen -S celery
celery -A worker.celery_app worker --loglevel=info --concurrency=2
```

## ğŸ’° ë¹„ìš© ê´€ë¦¬

### ì‘ì—… ì™„ë£Œ í›„ Pod ì¤‘ì§€
```
RunPod Dashboard â†’ Pods â†’ territorial_amaranth_mastodon
â†’ Stop ë²„íŠ¼ í´ë¦­
â†’ ì‹œê°„ë‹¹ ë¹„ìš© ì¤‘ë‹¨
â†’ ë””ìŠ¤í¬ ë°ì´í„° 24ì‹œê°„ ìœ ì§€
```

### ë‹¤ì‹œ ì‹œì‘
```
Pods â†’ territorial_amaranth_mastodon â†’ Start
â†’ 2-3ë¶„ ëŒ€ê¸°
â†’ ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ í•„ìš” (5ë¶„)
â†’ Celery Worker ì¬ì‹œì‘
```

### ì™„ì „ ì¢…ë£Œ (í”„ë¡œì íŠ¸ ì¢…ë£Œ ì‹œ)
```
Pods â†’ territorial_amaranth_mastodon â†’ Terminate
â†’ ëª¨ë“  ë°ì´í„° ì‚­ì œ
â†’ ë¹„ìš© ì™„ì „ ì¤‘ë‹¨
```

## ğŸ“ ì§€ì›

ë¬¸ì œ ë°œìƒ ì‹œ:
1. `screen -r celery`ë¡œ Worker ë¡œê·¸ í™•ì¸
2. `nvidia-smi`ë¡œ GPU ì‚¬ìš©ë¥  í™•ì¸
3. Flower ëŒ€ì‹œë³´ë“œì—ì„œ Task ìƒíƒœ í™•ì¸
4. EC2 FastAPI ë¡œê·¸ í™•ì¸

í™”ì´íŒ…! ğŸš€
